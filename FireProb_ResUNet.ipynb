{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388a910a-e683-4d3f-86af-ae6062c25af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opendatasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cccc1bf-3964-4c39-852a-c697888870c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Not working on Google Colab, due to limited System RAM (12.7 GB) and our large dataset zip file (14 GB)\n",
    "# # Dataset already present on local device\n",
    "\n",
    "# import opendatasets as od\n",
    "# od.download(\"https://www.kaggle.com/datasets/prajwalmohapatra/stacked-fire-probability-prediction-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a01cb02-a2fb-43a3-9fa9-4cef0d826cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model code already present on local device\n",
    "\n",
    "# !git clone git@github.com:Prajwal-Mohapatra/forest_fire_spread.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce9455a-6e1e-431b-9733-3120632a51ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/swayam/projects/forest_fire_spread/fire_prediction_model\n"
     ]
    }
   ],
   "source": [
    "%cd fire_prediction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d4c8c9-cb2e-473c-89df-6b59ce0bd388",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e764211b-6dcb-410e-a5f7-2d498f96849b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:22:49.341254: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Received dilation rates: [1, 2, 4, 8]\n",
      "Received dilation rates are not defined on a per downsampling level basis.\n",
      "Automated determinations are applied with the following details:\n",
      "\tdepth-0, dilation_rate = [1, 2, 4, 8]\n",
      "\tdepth-1, dilation_rate = [1, 2, 4, 8]\n",
      "\tdepth-2, dilation_rate = [1, 2, 4]\n",
      "\tdepth-3, dilation_rate = [1]\n",
      "2025-07-04 17:22:51.143830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-04 17:22:51.178141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-04 17:22:51.178672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-04 17:22:51.179212: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-04 17:22:51.180327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-04 17:22:51.180809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-04 17:22:51.181212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-04 17:22:51.287318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-04 17:22:51.287754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-04 17:22:51.288097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-04 17:22:51.288292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2791 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "✅ Dataset loaded successfully! 1800 patches available.\n",
      "✅ Dataset loaded successfully! 140 patches available.\n",
      "Epoch 1/30\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/swayam/projects/forest_fire_spread/fire_prediction_model/train.py\", line 57, in <module>\n",
      "    history = model.fit(\n",
      "  File \"/home/swayam/miniconda3/envs/forest_fire/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/tmp/__autograph_generated_filed2yjqtzg.py\", line 15, in tf__train_function\n",
      "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "  File \"/tmp/__autograph_generated_filevmyd2mpq.py\", line 10, in tf__weighted_bce\n",
      "    weights = ag__.converted_call(ag__.ld(compute_class_weight), (ag__.ld(y_true),), None, fscope)\n",
      "  File \"/tmp/__autograph_generated_file3zb3rbn3.py\", line 35, in tf__compute_class_weight\n",
      "    ag__.for_stmt(ag__.ld(mask_batch), None, loop_body, get_state, set_state, (), {'iterate_names': 'mask'})\n",
      "  File \"/tmp/__autograph_generated_file3zb3rbn3.py\", line 25, in loop_body\n",
      "    pos = ag__.converted_call(ag__.ld(np).sum, (ag__.ld(mask) == 1,), None, fscope)\n",
      "  File \"/home/swayam/miniconda3/envs/forest_fire/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 2313, in sum\n",
      "    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n",
      "  File \"/home/swayam/miniconda3/envs/forest_fire/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 88, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "NotImplementedError: in user code:\n",
      "\n",
      "    File \"/home/swayam/miniconda3/envs/forest_fire/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"/home/swayam/projects/forest_fire_spread/fire_prediction_model/train.py\", line 14, in weighted_bce  *\n",
      "        weights = compute_class_weight(y_true)\n",
      "    File \"/home/swayam/projects/forest_fire_spread/fire_prediction_model/dataset/preprocess.py\", line 20, in compute_class_weight  *\n",
      "        pos = np.sum(mask == 1)\n",
      "    File \"/home/swayam/miniconda3/envs/forest_fire/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 2313, in sum  **\n",
      "        return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n",
      "    File \"/home/swayam/miniconda3/envs/forest_fire/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 88, in _wrapreduction\n",
      "        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "\n",
      "    NotImplementedError: Cannot convert a symbolic tf.Tensor (weighted_bce/while/Equal:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forest_fire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
